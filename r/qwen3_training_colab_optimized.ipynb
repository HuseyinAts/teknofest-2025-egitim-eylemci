{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab-title"
   },
   "source": [
    "# ğŸš€ QWEN3-8B Turkish Training - Google Colab Optimized\n",
    "\n",
    "## Production Ready v4.0 ULTIMATE - Colab Edition\n",
    "\n",
    "Bu notebook, QWEN3 modelini TÃ¼rkÃ§e veri setiyle eÄŸitmek iÃ§in Ã¶zel olarak Google Colab'a optimize edilmiÅŸtir.\n",
    "\n",
    "### ğŸ¯ Ã–zellikler:\n",
    "- âœ… Deterministic tokenization\n",
    "- âœ… Memory efficient EMA and teacher caching\n",
    "- âœ… Updated dependencies\n",
    "- âœ… Comprehensive error recovery\n",
    "- âœ… Config validation layer\n",
    "- âœ… Health monitoring dashboard\n",
    "- âœ… Mixed precision auto-detection\n",
    "- âœ… Dataset streaming\n",
    "- âœ… Advanced auto-tuning\n",
    "- âœ… Google Colab optimized\n",
    "- âœ… Interactive widgets\n",
    "\n",
    "### ğŸ“‹ Gereksinimler:\n",
    "- Google Colab Pro (Ã¶nerilen) veya Ã¼cretsiz GPU\n",
    "- Google Drive (model ve checkpoint'leri kaydetmek iÃ§in)\n",
    "\n",
    "### ğŸš€ KullanÄ±m:\n",
    "1. Runtime > Change runtime type > GPU seÃ§in\n",
    "2. TÃ¼m hÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n\n",
    "3. EÄŸitim ilerlemesini izleyin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## ğŸ”§ 1. Kurulum ve HazÄ±rlÄ±k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports-and-setup",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ğŸ“¦ KÃ¼tÃ¼phaneler ve BaÅŸlangÄ±Ã§ AyarlarÄ± { display-mode: \"form\" }\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import gc\n",
    "import time\n",
    "import hashlib\n",
    "import traceback\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, List, Union, Tuple, Callable\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from abc import ABC, abstractmethod\n",
    "from functools import lru_cache, wraps\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import psutil\n",
    "import platform\n",
    "import subprocess\n",
    "from contextlib import contextmanager\n",
    "import threading\n",
    "from queue import Queue\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Google Colab detection\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"ğŸ” Google Colab ortamÄ±: {'âœ… Tespit edildi' if IS_COLAB else 'âŒ BulunamadÄ±'}\")\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive, output, files\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "    import ipywidgets as widgets\n",
    "    \n",
    "    # Enable widgets\n",
    "    output.enable_custom_widget_manager()\n",
    "    \n",
    "    print(\"ğŸ“± Google Colab widget'larÄ± etkinleÅŸtirildi\")\n",
    "else:\n",
    "    print(\"âš ï¸ Bu notebook Google Colab iÃ§in optimize edilmiÅŸtir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drive-mount",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ğŸ’¾ Google Drive BaÄŸlama { display-mode: \"form\" }\n",
    "\n",
    "if IS_COLAB:\n",
    "    try:\n",
    "        print(\"ğŸ”— Google Drive baÄŸlanÄ±yor...\")\n",
    "        drive.mount('/content/drive', force_remount=True)\n",
    "        DRIVE_PATH = Path('/content/drive/MyDrive/qwen_training')\n",
    "        DRIVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"âœ… Google Drive baÅŸarÄ±yla baÄŸlandÄ±: {DRIVE_PATH}\")\n",
    "        \n",
    "        # Create subdirectories\n",
    "        (DRIVE_PATH / 'checkpoints').mkdir(exist_ok=True)\n",
    "        (DRIVE_PATH / 'logs').mkdir(exist_ok=True)\n",
    "        (DRIVE_PATH / 'models').mkdir(exist_ok=True)\n",
    "        print(\"ğŸ“ KlasÃ¶r yapÄ±sÄ± oluÅŸturuldu\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Google Drive baÄŸlantÄ±sÄ± baÅŸarÄ±sÄ±z: {e}\")\n",
    "        print(\"ğŸ“‚ Yerel dizin kullanÄ±lacak\")\n",
    "        DRIVE_PATH = Path('/content/qwen_training')\n",
    "        DRIVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "else:\n",
    "    DRIVE_PATH = Path('./qwen_training')\n",
    "    DRIVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“ Ã‡alÄ±ÅŸma dizini: {DRIVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpu-check",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ğŸ–¥ï¸ GPU Durumu KontrolÃ¼ { display-mode: \"form\" }\n",
    "\n",
    "if IS_COLAB:\n",
    "    # Check GPU availability\n",
    "    import subprocess\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"ğŸ® GPU Bilgileri:\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(\"âŒ GPU bulunamadÄ±. Runtime > Change runtime type > GPU seÃ§in\")\n",
    "        \n",
    "    # Check GPU type and memory\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "            print(f\"\\nğŸš€ GPU: {gpu_name}\")\n",
    "            print(f\"ğŸ’¾ VRAM: {gpu_memory:.1f} GB\")\n",
    "            \n",
    "            # Colab specific recommendations\n",
    "            if 'T4' in gpu_name:\n",
    "                print(\"ğŸ“ T4 GPU tespit edildi - Ãœcretsiz Colab tier\")\n",
    "                print(\"ğŸ’¡ KÃ¼Ã§Ã¼k batch size ve hafif model Ã¶nerilir\")\n",
    "            elif 'P100' in gpu_name:\n",
    "                print(\"ğŸ“ P100 GPU tespit edildi - Colab Pro\")\n",
    "                print(\"ğŸ’¡ Orta seviye training mÃ¼mkÃ¼n\")\n",
    "            elif 'V100' in gpu_name:\n",
    "                print(\"ğŸ“ V100 GPU tespit edildi - Colab Pro+\")\n",
    "                print(\"ğŸ’¡ YÃ¼ksek performanslÄ± training mÃ¼mkÃ¼n\")\n",
    "            elif 'A100' in gpu_name:\n",
    "                print(\"ğŸ“ A100 GPU tespit edildi - Premium\")\n",
    "                print(\"ğŸ’¡ Maximum performans training mÃ¼mkÃ¼n\")\n",
    "        else:\n",
    "            print(\"âŒ CUDA GPU bulunamadÄ±\")\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ PyTorch henÃ¼z yÃ¼klenmedi\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ Lokal ortam - GPU durumunu manuel kontrol edin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-section"
   },
   "source": [
    "## ğŸ“¦ 2. Paket Kurulumu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-packages",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ğŸ”§ Gerekli Paketlerin Kurulumu { display-mode: \"form\" }\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install required packages optimized for Google Colab\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“¦ Paket kurulumu baÅŸlÄ±yor...\")\n",
    "    \n",
    "    # Core packages for Colab\n",
    "    REQUIRED_PACKAGES = [\n",
    "        \"transformers\",\n",
    "        \"datasets\", \n",
    "        \"accelerate\",\n",
    "        \"peft\",\n",
    "        \"bitsandbytes\",\n",
    "        \"sentencepiece\",\n",
    "        \"tiktoken\",\n",
    "        \"trl\",\n",
    "        \"psutil\",\n",
    "        \"einops\",\n",
    "        \"safetensors\"\n",
    "    ]\n",
    "    \n",
    "    OPTIONAL_PACKAGES = [\n",
    "        \"wandb\"\n",
    "    ]\n",
    "    \n",
    "    def install_package(package: str, upgrade: bool = False) -> bool:\n",
    "        try:\n",
    "            cmd = f\"pip install -q {'--upgrade' if upgrade else ''} {package}\"\n",
    "            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                print(f\"âœ… {package}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"âŒ {package}: {result.stderr[:100]}...\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {package}: {str(e)[:100]}...\")\n",
    "            return False\n",
    "    \n",
    "    # Install core packages\n",
    "    print(\"\\nğŸ”§ Temel paketler kuruluyor...\")\n",
    "    for package in REQUIRED_PACKAGES:\n",
    "        install_package(package)\n",
    "    \n",
    "    # Install optional packages\n",
    "    print(\"\\nğŸ”§ Opsiyonel paketler kuruluyor...\")\n",
    "    for package in OPTIONAL_PACKAGES:\n",
    "        try:\n",
    "            install_package(package)\n",
    "        except:\n",
    "            print(f\"âš ï¸ {package} atlandÄ±\")\n",
    "    \n",
    "    print(\"\\nâœ… Paket kurulumu tamamlandÄ±!\")\n",
    "\n",
    "# Run installation\n",
    "install_packages()\n",
    "\n",
    "# Import check\n",
    "try:\n",
    "    import torch\n",
    "    import transformers\n",
    "    print(f\"\\nğŸ“Š PyTorch: {torch.__version__}\")\n",
    "    print(f\"ğŸ“Š Transformers: {transformers.__version__}\")\n",
    "    print(f\"ğŸ“Š CUDA Available: {torch.cuda.is_available()}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸ Import hatasÄ±: {e}\")\n",
    "    print(\"ğŸ”„ LÃ¼tfen runtime'Ä± restart edin ve tekrar deneyin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-section"
   },
   "source": [
    "## âš™ï¸ 3. EÄŸitim YapÄ±landÄ±rmasÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-config-interactive",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title ğŸ¯ EÄŸitim Parametreleri { display-mode: \"form\" }\n",
    "\n",
    "# Interactive configuration for Colab\n",
    "model_name = \"microsoft/phi-2\" #@param [\"microsoft/phi-2\", \"Qwen/Qwen2.5-7B-Instruct\", \"Qwen/Qwen2-7B\"] {type:\"string\"}\n",
    "num_epochs = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
    "learning_rate = 0.00002 #@param {type:\"number\"}\n",
    "batch_size = 1 #@param {type:\"slider\", min:1, max:8, step:1}\n",
    "gradient_accumulation_steps = 8 #@param {type:\"slider\", min:1, max:32, step:1}\n",
    "max_length = 256 #@param {type:\"slider\", min:128, max:1024, step:64}\n",
    "use_lora = True #@param {type:\"boolean\"}\n",
    "lora_rank = 8 #@param {type:\"slider\", min:4, max:64, step:4}\n",
    "use_4bit = True #@param {type:\"boolean\"}\n",
    "max_train_samples = 1000 #@param {type:\"slider\", min:100, max:10000, step:100}\n",
    "\n",
    "print(f\"ğŸ“Š SeÃ§ilen Model: {model_name}\")\n",
    "print(f\"ğŸ“Š Epoch SayÄ±sÄ±: {num_epochs}\")\n",
    "print(f\"ğŸ“Š Learning Rate: {learning_rate}\")\n",
    "print(f\"ğŸ“Š Batch Size: {batch_size}\")\n",
    "print(f\"ğŸ“Š Gradient Accumulation: {gradient_accumulation_steps}\")\n",
    "print(f\"ğŸ“Š Max Length: {max_length}\")\n",
    "print(f\"ğŸ“Š LoRA: {'âœ…' if use_lora else 'âŒ'}\")\n",
    "print(f\"ğŸ“Š 4-bit Quantization: {'âœ…' if use_4bit else 'âŒ'}\")\n",
    "print(f\"ğŸ“Š Max Train Samples: {max_train_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training-section"
   },
   "source": [
    "## ğŸ¯ 4. Ana EÄŸitim Kodu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "main-training-code"
   },
   "outputs": [],
   "source": [
    "# Import the main training script\n",
    "exec(open('/content/drive/MyDrive/qwen_training/qwen3_training_production_v4_fixed.py').read()) if IS_COLAB else None\n",
    "\n",
    "# Or run training directly\n",
    "if not IS_COLAB:\n",
    "    print(\"âš ï¸ Bu notebook Google Colab iÃ§in tasarlanmÄ±ÅŸtÄ±r.\")\n",
    "    print(\"Lokal Ã§alÄ±ÅŸtÄ±rma iÃ§in qwen3_training_production_v4_fixed.py dosyasÄ±nÄ± kullanÄ±n.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}