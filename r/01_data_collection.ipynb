{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection - Turkish Educational Datasets\n",
    "## TEKNOFEST 2025 - Eğitim Teknolojileri\n",
    "\n",
    "Bu notebook, Türkçe eğitim veri setlerini toplamak için kullanılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri import et\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Proje root'unu path'e ekle\n",
    "sys.path.append('../')\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face datasets kütüphanesini yükle\n",
    "try:\n",
    "    from datasets import load_dataset\n",
    "    print(\"[OK] datasets library is available\")\n",
    "except ImportError:\n",
    "    print(\"[INFO] Installing datasets library...\")\n",
    "    !pip install datasets\n",
    "    from datasets import load_dataset\n",
    "    print(\"[OK] datasets library installed and imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turkish Quiz Instruct Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face'ten Turkish Quiz dataset'ini indir\n",
    "print(\"Downloading Turkish Quiz Instruct dataset...\")\n",
    "\n",
    "try:\n",
    "    dataset = load_dataset(\"Kamyar-zeinalipour/Turkish-Quiz-Instruct\")\n",
    "    print(f\"[OK] Dataset loaded successfully\")\n",
    "    print(f\"Available splits: {list(dataset.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to load dataset: {e}\")\n",
    "    dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset bilgilerini göster\n",
    "if dataset is not None:\n",
    "    train_data = dataset['train']\n",
    "    print(f\"\\nDataset Info:\")\n",
    "    print(f\"- Number of examples: {len(train_data)}\")\n",
    "    print(f\"- Features: {train_data.features}\")\n",
    "    \n",
    "    # İlk birkaç örneği göster\n",
    "    print(\"\\nFirst 3 examples:\")\n",
    "    for i in range(min(3, len(train_data))):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        for key, value in train_data[i].items():\n",
    "            print(f\"  {key}: {str(value)[:100]}...\" if len(str(value)) > 100 else f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV olarak kaydet\n",
    "if dataset is not None:\n",
    "    output_path = '../data/raw/turkish_quiz_instruct.csv'\n",
    "    \n",
    "    # Dizin yoksa oluştur\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # DataFrame'e çevir ve kaydet\n",
    "    df = pd.DataFrame(dataset['train'])\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"[OK] {len(df)} examples saved to {output_path}\")\n",
    "    print(f\"File size: {os.path.getsize(output_path) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Turkish Educational Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diğer Türkçe eğitim datasetleri listesi\n",
    "turkish_datasets = [\n",
    "    \"turkish-nlp-suite/turkish-texts\",\n",
    "    \"ertugruldemir/TurkishNLP\",\n",
    "    # Daha fazla dataset eklenebilir\n",
    "]\n",
    "\n",
    "print(\"Other available Turkish datasets:\")\n",
    "for ds_name in turkish_datasets:\n",
    "    print(f\"- {ds_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri istatistikleri\n",
    "if os.path.exists('../data/raw/turkish_quiz_instruct.csv'):\n",
    "    df = pd.read_csv('../data/raw/turkish_quiz_instruct.csv')\n",
    "    \n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(f\"- Total rows: {len(df)}\")\n",
    "    print(f\"- Total columns: {len(df.columns)}\")\n",
    "    print(f\"- Column names: {list(df.columns)}\")\n",
    "    print(f\"\\nMemory usage: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "    \n",
    "    # Null değerleri kontrol et\n",
    "    print(\"\\nNull values per column:\")\n",
    "    print(df.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}