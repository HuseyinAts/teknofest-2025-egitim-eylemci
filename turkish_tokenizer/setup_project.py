#!/usr/bin/env python3
"""
TÃ¼rkÃ§e Tokenizer Proje Kurulumu
Bu script, Qwen3-8B iÃ§in TÃ¼rkÃ§e tokenizer geliÅŸtirme projesinin
tÃ¼m klasÃ¶r yapÄ±sÄ±nÄ± ve temel dosyalarÄ±nÄ± oluÅŸturur.
"""

import os
import sys
from pathlib import Path

def create_directory_structure():
    """Proje klasÃ¶r yapÄ±sÄ±nÄ± oluÅŸtur"""
    
    # Ana proje dizini
    base_dir = Path("c:/Users/husey/teknofest-2025-egitim-eylemci/turkish_tokenizer")
    
    # OluÅŸturulacak klasÃ¶rler
    directories = [
        "data/raw",
        "data/processed", 
        "data/tokenizer_data",
        "vocab_analysis",
        "tokenizer_extension",
        "training",
        "evaluation",
        "models/qwen3_original",
        "models/qwen3_turkish",
        "scripts",
        "configs",
        "notebooks",
        "results",
        "logs"
    ]
    
    print("ğŸš€ TÃ¼rkÃ§e Tokenizer Proje YapÄ±sÄ± OluÅŸturuluyor...")
    
    for directory in directories:
        dir_path = base_dir / directory
        dir_path.mkdir(parents=True, exist_ok=True)
        print(f"âœ… OluÅŸturuldu: {directory}")
    
    # __init__.py dosyalarÄ±nÄ± oluÅŸtur
    python_dirs = ["vocab_analysis", "tokenizer_extension", "training", "evaluation"]
    for dir_name in python_dirs:
        init_file = base_dir / dir_name / "__init__.py"
        init_file.touch(exist_ok=True)
    
    print("\nğŸ“ Proje klasÃ¶r yapÄ±sÄ± baÅŸarÄ±yla oluÅŸturuldu!")

def create_requirements_file():
    """Gerekli paketlerin listesini oluÅŸtur"""
    base_dir = Path("c:/Users/husey/teknofest-2025-egitim-eylemci/turkish_tokenizer")
    
    requirements = """# TÃ¼rkÃ§e Tokenizer GeliÅŸtirme Ä°Ã§in Gerekli Paketler

# Temel ML/NLP kÃ¼tÃ¼phaneleri
torch>=2.0.0
transformers>=4.35.0
tokenizers>=0.15.0
datasets>=2.14.0

# Qwen3 modeli iÃ§in
safetensors>=0.4.0
accelerate>=0.24.0

# Veri iÅŸleme
pandas>=2.0.0
numpy>=1.24.0
scipy>=1.10.0

# TÃ¼rkÃ§e NLP
zeyrek  # TÃ¼rkÃ§e morfotaktik analiz
turkish-stemmer  # TÃ¼rkÃ§e gÃ¶vdeleme

# GÃ¶rselleÅŸtirme ve analiz
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.15.0
wordcloud>=1.9.0

# Metin iÅŸleme
regex>=2023.8.8
sentencepiece>=0.1.99

# Progress bars ve utilities
tqdm>=4.65.0
rich>=13.5.0

# Jupyter notebook
jupyter>=1.0.0
ipykernel>=6.25.0

# Test ve kalite kontrolÃ¼
pytest>=7.4.0
black>=23.7.0
"""
    
    req_file = base_dir / "requirements.txt"
    with open(req_file, 'w', encoding='utf-8') as f:
        f.write(requirements)
    
    print("ğŸ“‹ requirements.txt dosyasÄ± oluÅŸturuldu!")

def create_config_files():
    """YapÄ±landÄ±rma dosyalarÄ±nÄ± oluÅŸtur"""
    base_dir = Path("c:/Users/husey/teknofest-2025-egitim-eylemci/turkish_tokenizer")
    
    # Ana yapÄ±landÄ±rma dosyasÄ±
    config_content = """# TÃ¼rkÃ§e Tokenizer YapÄ±landÄ±rmasÄ±

# Model bilgileri
MODEL_NAME: "Qwen/Qwen2.5-8B"
MODEL_PATH: "models/qwen3_original"
TURKISH_MODEL_PATH: "models/qwen3_turkish"

# Veri yollarÄ±
DATA_RAW_PATH: "../data/raw/turkish_quiz_instruct.csv"
DATA_PROCESSED_PATH: "../data/processed/competition_dataset.jsonl"
TOKENIZER_DATA_PATH: "data/tokenizer_data"

# Tokenizer ayarlarÄ±
ORIGINAL_VOCAB_SIZE: 151936
TURKISH_VOCAB_SIZE: 50000  # Eklenecek TÃ¼rkÃ§e token sayÄ±sÄ±
TOTAL_VOCAB_SIZE: 201936

# EÄŸitim ayarlarÄ±
BATCH_SIZE: 16
LEARNING_RATE: 5e-5
NUM_EPOCHS: 3
MAX_LENGTH: 2048

# DonanÄ±m ayarlarÄ±
DEVICE: "cuda"  # veya "cpu"
MIXED_PRECISION: true
GRADIENT_CHECKPOINTING: true

# TÃ¼rkÃ§e Ã¶zel ayarlar
TURKISH_SUFFIXES: ["-ler", "-lar", "-de", "-da", "-den", "-dan", "-ye", "-ya", "-nin", "-nÄ±n", "-nÃ¼n", "-nun"]
MORPHEME_AWARE: true
VOWEL_HARMONY: true

# DeÄŸerlendirme ayarlarÄ±
EVAL_BATCH_SIZE: 32
EVAL_STEPS: 500
SAVE_STEPS: 1000

# Ã‡Ä±ktÄ± ayarlarÄ±
LOG_LEVEL: "INFO"
SAVE_TOTAL_LIMIT: 3
"""
    
    config_file = base_dir / "configs" / "config.yaml"
    with open(config_file, 'w', encoding='utf-8') as f:
        f.write(config_content)
    
    print("âš™ï¸ config.yaml dosyasÄ± oluÅŸturuldu!")

if __name__ == "__main__":
    print("ğŸ‡¹ğŸ‡· Qwen3-8B TÃ¼rkÃ§e Tokenizer Proje Kurulumu")
    print("=" * 50)
    
    create_directory_structure()
    create_requirements_file() 
    create_config_files()
    
    print("\nğŸ‰ Proje kurulumu tamamlandÄ±!")
    print("\nğŸ“‹ SÄ±radaki adÄ±mlar:")
    print("1. cd turkish_tokenizer")
    print("2. pip install -r requirements.txt")
    print("3. python scripts/analyze_turkish_data.py")