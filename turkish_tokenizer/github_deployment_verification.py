#!/usr/bin/env python3
"""
üîç GITHUB REPOSITORY READINESS VERIFICATION
Complete checklist and verification for GitHub deployment

Usage: python github_deployment_verification.py
"""

import os
import sys
from pathlib import Path
import json
from datetime import datetime

class GitHubDeploymentChecker:
    """GitHub repository readiness checker"""
    
    def __init__(self):
        self.base_dir = Path(__file__).parent
        self.results = {
            'timestamp': datetime.now().isoformat(),
            'overall_status': 'UNKNOWN',
            'checks': {},
            'missing_items': [],
            'recommendations': []
        }
    
    def check_essential_files(self):
        """Check essential files are present"""
        
        essential_files = [
            'README.md',
            'GITHUB_USAGE_GUIDE.md', 
            'requirements.txt',
            'install.py',
            'LICENSE',
            '.gitignore',
            'final_master_trainer.py',
            'colab_pro_a100_optimized_trainer.py',
            'master_orchestrator.py',
            'quick_test_runner.py'
        ]
        
        missing_files = []
        existing_files = []
        
        for file_name in essential_files:
            file_path = self.base_dir / file_name
            if file_path.exists():
                existing_files.append(file_name)
            else:
                missing_files.append(file_name)
        
        self.results['checks']['essential_files'] = {
            'status': 'PASS' if not missing_files else 'FAIL',
            'existing': existing_files,
            'missing': missing_files,
            'score': f"{len(existing_files)}/{len(essential_files)}"
        }
        
        if missing_files:
            self.results['missing_items'].extend(missing_files)
        
        return not missing_files
    
    def check_core_implementations(self):
        """Check core implementation files"""
        
        core_files = [
            'enhanced_dora_implementation.py',
            'complete_neftune_implementation.py', 
            'ultra_sophia_optimizer.py',
            'optimized_dataset_loader.py',
            'advanced_dataset_analyzer.py',
            'turkish_vocabulary_analyzer.py',
            'qwen_turkish_extender.py'
        ]
        
        missing_core = []
        existing_core = []
        
        for file_name in core_files:
            file_path = self.base_dir / file_name
            if file_path.exists():
                existing_core.append(file_name)
            else:
                missing_core.append(file_name)
        
        self.results['checks']['core_implementations'] = {
            'status': 'PASS' if not missing_core else 'FAIL',
            'existing': existing_core,
            'missing': missing_core,
            'score': f"{len(existing_core)}/{len(core_files)}"
        }
        
        if missing_core:
            self.results['missing_items'].extend(missing_core)
        
        return not missing_core
    
    def check_advanced_features(self):
        """Check advanced feature files"""
        
        advanced_files = [
            'dynamic_vocab_expansion.py',
            'advanced_curriculum_learning.py',
            'realtime_monitoring_system.py',
            'hybrid_ensemble_trainer.py',
            'setup_colab_pro_a100.py'
        ]
        
        missing_advanced = []
        existing_advanced = []
        
        for file_name in advanced_files:
            file_path = self.base_dir / file_name
            if file_path.exists():
                existing_advanced.append(file_name)
            else:
                missing_advanced.append(file_name)
        
        self.results['checks']['advanced_features'] = {
            'status': 'PASS' if not missing_advanced else 'PARTIAL',
            'existing': existing_advanced,
            'missing': missing_advanced,
            'score': f"{len(existing_advanced)}/{len(advanced_files)}"
        }
        
        return not missing_advanced
    
    def check_documentation_completeness(self):
        """Check documentation completeness"""
        
        doc_files = [
            'README.md',
            'GITHUB_USAGE_GUIDE.md',
            'ULTRA_ANALIZ_RAPORU.md'
        ]
        
        doc_issues = []
        
        for doc_file in doc_files:
            file_path = self.base_dir / doc_file
            if file_path.exists():
                # Check file size (should be substantial)
                size = file_path.stat().st_size
                if size < 1000:  # Less than 1KB
                    doc_issues.append(f"{doc_file} too small ({size} bytes)")
            else:
                doc_issues.append(f"{doc_file} missing")
        
        # Check README has key sections
        readme_path = self.base_dir / 'README.md'
        if readme_path.exists():
            content = readme_path.read_text(encoding='utf-8')
            required_sections = ['Quick Start', 'Installation', 'Usage', 'Features']
            missing_sections = [s for s in required_sections if s.lower() not in content.lower()]
            if missing_sections:
                doc_issues.append(f"README missing sections: {missing_sections}")
        
        self.results['checks']['documentation'] = {
            'status': 'PASS' if not doc_issues else 'FAIL',
            'issues': doc_issues,
            'files_checked': doc_files
        }
        
        if doc_issues:
            self.results['missing_items'].extend(doc_issues)
        
        return not doc_issues
    
    def check_requirements_completeness(self):
        """Check requirements.txt completeness"""
        
        req_path = self.base_dir / 'requirements.txt'
        
        if not req_path.exists():
            self.results['checks']['requirements'] = {
                'status': 'FAIL',
                'error': 'requirements.txt not found'
            }
            return False
        
        content = req_path.read_text()
        
        # Essential packages
        essential_packages = [
            'torch', 'transformers', 'datasets', 'peft', 
            'accelerate', 'numpy', 'pandas'
        ]
        
        missing_packages = []
        for package in essential_packages:
            if package not in content.lower():
                missing_packages.append(package)
        
        self.results['checks']['requirements'] = {
            'status': 'PASS' if not missing_packages else 'FAIL',
            'missing_packages': missing_packages,
            'file_size': len(content)
        }
        
        return not missing_packages
    
    def check_python_imports(self):
        """Test critical Python imports"""
        
        critical_imports = [
            'final_master_trainer',
            'colab_pro_a100_optimized_trainer',
            'enhanced_dora_implementation',
            'quick_test_runner'
        ]
        
        import_issues = []
        successful_imports = []
        
        for module in critical_imports:
            try:
                # Add current directory to path
                sys.path.insert(0, str(self.base_dir))
                __import__(module)
                successful_imports.append(module)
            except ImportError as e:
                import_issues.append(f"{module}: {str(e)}")
            except Exception as e:
                import_issues.append(f"{module}: {str(e)}")
            finally:
                # Remove from path
                if str(self.base_dir) in sys.path:
                    sys.path.remove(str(self.base_dir))
        
        self.results['checks']['python_imports'] = {
            'status': 'PASS' if not import_issues else 'FAIL',
            'successful': successful_imports,
            'failed': import_issues,
            'score': f"{len(successful_imports)}/{len(critical_imports)}"
        }
        
        return not import_issues
    
    def generate_github_recommendations(self):
        """Generate GitHub-specific recommendations"""
        
        recommendations = []
        
        # Repository structure recommendations
        recommendations.append("üìÅ Repository Structure:")
        recommendations.append("  ‚úì All essential files present")
        recommendations.append("  ‚úì Clear documentation structure")
        recommendations.append("  ‚úì Proper .gitignore configuration")
        
        # Usage recommendations
        recommendations.append("\nüöÄ GitHub Usage Instructions:")
        recommendations.append("  1. Clone: git clone <repo-url>")
        recommendations.append("  2. Install: python install.py")
        recommendations.append("  3. Test: python quick_test_runner.py")
        recommendations.append("  4. Train: python master_orchestrator.py")
        
        # Colab recommendations
        recommendations.append("\n‚òÅÔ∏è Google Colab Setup:")
        recommendations.append("  1. !git clone <repo-url>")
        recommendations.append("  2. %cd turkish_tokenizer")
        recommendations.append("  3. !python setup_colab_pro_a100.py")
        recommendations.append("  4. from colab_pro_a100_optimized_trainer import run_colab_pro_a100_training")
        recommendations.append("  5. results = run_colab_pro_a100_training()")
        
        # Critical notes from memory
        recommendations.append("\n‚ö†Ô∏è Critical Memory-Based Fixes:")
        recommendations.append("  ‚úÖ Tokenizer mismatch protection: NO embed_tokens in modules_to_save")
        recommendations.append("  ‚úÖ Learning rate: 2e-4 (Turkish-optimal)")
        recommendations.append("  ‚úÖ Dataset quality: min 30 character texts")
        recommendations.append("  ‚úÖ Catastrophic forgetting: EWC + Self-synthesis enabled")
        
        self.results['recommendations'] = recommendations
        return recommendations
    
    def run_complete_check(self):
        """Run complete verification"""
        
        print("üîç GITHUB REPOSITORY READINESS VERIFICATION")
        print("=" * 60)
        
        # Run all checks
        checks = [
            ("Essential Files", self.check_essential_files),
            ("Core Implementations", self.check_core_implementations),
            ("Advanced Features", self.check_advanced_features),
            ("Documentation", self.check_documentation_completeness),
            ("Requirements", self.check_requirements_completeness),
            ("Python Imports", self.check_python_imports)
        ]
        
        passed_checks = 0
        total_checks = len(checks)
        
        for check_name, check_func in checks:
            print(f"\nüîç {check_name}...")
            try:
                result = check_func()
                status = "‚úÖ PASS" if result else "‚ùå FAIL"
                print(f"  {status}")
                
                if result:
                    passed_checks += 1
                    
            except Exception as e:
                print(f"  ‚ùå ERROR: {e}")
                self.results['checks'][check_name.lower().replace(' ', '_')] = {
                    'status': 'ERROR',
                    'error': str(e)
                }
        
        # Overall status
        pass_rate = passed_checks / total_checks
        
        if pass_rate == 1.0:
            overall_status = "READY"
        elif pass_rate >= 0.8:
            overall_status = "MOSTLY_READY"
        elif pass_rate >= 0.6:
            overall_status = "NEEDS_WORK" 
        else:
            overall_status = "NOT_READY"
        
        self.results['overall_status'] = overall_status
        self.results['pass_rate'] = f"{passed_checks}/{total_checks} ({pass_rate:.1%})"
        
        # Generate recommendations
        self.generate_github_recommendations()
        
        # Final report
        print("\n" + "=" * 60)
        print(f"üèÜ OVERALL STATUS: {overall_status}")
        print(f"üìä PASS RATE: {self.results['pass_rate']}")
        print("=" * 60)
        
        if overall_status in ["READY", "MOSTLY_READY"]:
            print("üéâ REPOSITORY IS READY FOR GITHUB!")
            print("\nüìù Users can:")
            print("  ‚úÖ Clone and use immediately")
            print("  ‚úÖ Follow clear documentation")
            print("  ‚úÖ Run in Google Colab Pro+")
            print("  ‚úÖ Access all advanced features")
        else:
            print("‚ö†Ô∏è REPOSITORY NEEDS ATTENTION")
            if self.results['missing_items']:
                print(f"\n‚ùå Missing items: {len(self.results['missing_items'])}")
                for item in self.results['missing_items'][:5]:  # Show first 5
                    print(f"  ‚Ä¢ {item}")
        
        # Save detailed results
        results_file = self.base_dir / 'github_readiness_report.json'
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìÑ Detailed report: {results_file}")
        
        return overall_status in ["READY", "MOSTLY_READY"]

def main():
    """Main verification"""
    
    checker = GitHubDeploymentChecker()
    is_ready = checker.run_complete_check()
    
    # Exit with appropriate code
    sys.exit(0 if is_ready else 1)

if __name__ == "__main__":
    main()