# QWEN3 UYUMLU TÃœRKÃ‡E TOKENIZER GELÄ°ÅTÄ°RME ANALÄ°ZÄ°
# BaÅŸtan Ã¶zel TÃ¼rkÃ§e tokenizer geliÅŸtirmenin avantaj ve dezavantajlarÄ±

"""
PROBLEM: Mevcut turkish_mixtral_v3_fixed tokenizer Qwen3 ile uyumsuz
Ã‡Ã–ZUMLERÄ°N KARÅILAÅTIRMASI:
1. Hibrit yaklaÅŸÄ±mlar (Ã¶nceki analiz)
2. Qwen3'e Ã¶zel TÃ¼rkÃ§e tokenizer geliÅŸtirme (bu analiz)
"""

import json
from datetime import datetime

class Qwen3UyumluTurkceTokenizerAnalizi:
    """Qwen3 uyumlu TÃ¼rkÃ§e tokenizer geliÅŸtirme analizi"""
    
    def __init__(self):
        self.analiz_tarihi = datetime.now().strftime("%Y-%m-%d")
        
    def gelistirme_yaklasimlari(self):
        """
        TÃœRKÃ‡E TOKENIZER GELÄ°ÅTÄ°RME YAKLAÅIMLARI
        =======================================
        """
        
        return {
            "1. QWEN3 VOCABULARY EXTENSION": {
                "aciklama": "Mevcut Qwen3 vocabulary'sine TÃ¼rkÃ§e tokenlar ekleme",
                "yontem": "Qwen3'Ã¼n 151,936 tokenÄ±na ek TÃ¼rkÃ§e tokenlar ekleyerek geniÅŸletme",
                "teknik_yaklasim": [
                    "Qwen3 base vocabulary koruma",
                    "TÃ¼rkÃ§e-specific tokenlar ekleme",
                    "Vocabulary size artÄ±rma (Ã¶rn: 170,000-200,000)",
                    "Backward compatibility saÄŸlama"
                ],
                "gelistirme_suresi": "2-4 hafta",
                "zorluk_seviyesi": "â­â­â­",
                "basari_ihtimali": "85-90%"
            },
            
            "2. SIFIRDAN TÃœRKÃ‡E-OPTIMIZED TOKENIZER": {
                "aciklama": "SÄ±fÄ±rdan TÃ¼rkÃ§e dil yapÄ±sÄ±na optimize tokenizer",
                "yontem": "TÃ¼rkÃ§e morfoloji ve karakteristiklerine gÃ¶re Ã¶zel tasarÄ±m",
                "teknik_yaklasim": [
                    "TÃ¼rkÃ§e morfoloji analizi",
                    "Ek sistem optimization",
                    "Agglutinative dil yapÄ±sÄ± iÃ§in Ã¶zel algoritma",
                    "Turkish-specific vocabulary build"
                ],
                "gelistirme_suresi": "6-12 hafta",
                "zorluk_seviyesi": "â­â­â­â­â­",
                "basari_ihtimali": "60-75%"
            },
            
            "3. HYBRID VOCABULARY APPROACH": {
                "aciklama": "Qwen3 + TÃ¼rkÃ§e hibrit vocabulary tasarÄ±mÄ±",
                "yontem": "Ä°ki vocabulary'nin optimal birleÅŸimi",
                "teknik_yaklasim": [
                    "Qwen3 high-frequency tokens koruma",
                    "TÃ¼rkÃ§e-specific tokens ekleme",
                    "Overlap optimization",
                    "Balanced vocabulary distribution"
                ],
                "gelistirme_suresi": "3-6 hafta",
                "zorluk_seviyesi": "â­â­â­â­",
                "basari_ihtimali": "75-85%"
            }
        }
    
    def avantajlar_detayli_analiz(self):
        """
        TÃœRKÃ‡E TOKENIZER GELÄ°ÅTÄ°RMENÄ°N AVANTAJLARI
        =========================================
        """
        
        return {
            "PERFORMANS AVANTAJLARI": {
                "optimal_turkce_tokenization": {
                    "aciklama": "TÃ¼rkÃ§e iÃ§in en optimal token bÃ¶lÃ¼mleme",
                    "teknik_detaylar": [
                        "TÃ¼rkÃ§e morfoloji kurallarÄ±na uygun segmentation",
                        "Agglutinative yapÄ± iÃ§in optimize edilmiÅŸ tokenization",
                        "Ek sistem iÃ§in akÄ±llÄ± handling",
                        "Kelime kÃ¶kÃ¼ ve ek ayrÄ±mÄ± optimization"
                    ],
                    "beklenen_iyilestirme": "30-50% daha kÄ±sa token sequences",
                    "ornek": {
                        "kelime": "Ã§alÄ±ÅŸabileceklerinden",
                        "mevcut_tokenization": "['Ã§al', 'Ä±ÅŸ', 'abil', 'ecek', 'lerin', 'den'] (6 token)",
                        "optimize_tokenization": "['Ã§alÄ±ÅŸ', 'abil', 'ecek', 'lerinden'] (4 token)"
                    }
                },
                
                "vocabulary_efficiency": {
                    "aciklama": "TÃ¼rkÃ§e iÃ§in Ã¶zel vocabulary optimization",
                    "faydalar": [
                        "âœ… TÃ¼rkÃ§e high-frequency words iÃ§in dedicated tokens",
                        "âœ… Morfolojik pattern recognition",
                        "âœ… Reduced out-of-vocabulary (OOV) ratio",
                        "âœ… Better compression ratio for Turkish text"
                    ],
                    "beklenen_metrikler": {
                        "oov_ratio_azalmasi": "60-80%",
                        "compression_ratio_iyilestirmesi": "25-40%",
                        "tokenization_speed_artisi": "15-25%"
                    }
                },
                
                "model_performance_boost": {
                    "aciklama": "Model performance'Ä±nda genel iyileÅŸtirme",
                    "performance_alanlari": [
                        "âœ… Daha hÄ±zlÄ± inference (kÄ±sa sequences)",
                        "âœ… Daha iyi language understanding", 
                        "âœ… Improved generation quality",
                        "âœ… Better semantic representation"
                    ],
                    "beklenen_loss_iyilestirmesi": "0.5-1.0 puan dÃ¼ÅŸÃ¼k loss",
                    "inference_speed_artisi": "20-35%"
                }
            },
            
            "TEKNÄ°K AVANTAJLAR": {
                "perfect_compatibility": {
                    "aciklama": "Qwen3 ile mÃ¼kemmel uyumluluk",
                    "uyumluluk_alanlari": [
                        "âœ… Model architecture ile tam entegrasyon",
                        "âœ… Embedding layer perfect match",
                        "âœ… No vocabulary mismatch issues",
                        "âœ… Seamless fine-tuning capability"
                    ],
                    "sonuc": "Hibrit yaklaÅŸÄ±mlar gereksiz - direkt optimal training"
                },
                
                "scalability": {
                    "aciklama": "Gelecek geliÅŸtirmeler iÃ§in skalabilite",
                    "scalability_avantajlari": [
                        "âœ… TÃ¼rkÃ§e model ailesi iÃ§in foundation",
                        "âœ… Domain-specific tokenizer extensions",
                        "âœ… Multi-modal applications ready",
                        "âœ… Transfer learning optimized"
                    ]
                },
                
                "maintenance_simplicity": {
                    "aciklama": "Basit maintenance ve gÃ¼ncelleme",
                    "basitlik_avantajlari": [
                        "âœ… Single tokenizer solution",
                        "âœ… No complex hybrid logic",
                        "âœ… Straightforward debugging",
                        "âœ… Clear performance metrics"
                    ]
                }
            },
            
            "Ä°Å DEÄERÄ° AVANTAJLARI": {
                "intellectual_property": {
                    "aciklama": "Ã–zel tokenizer IP value",
                    "ip_degerleri": [
                        "âœ… Unique Turkish NLP technology",
                        "âœ… Competitive advantage in Turkish AI",
                        "âœ… Licensable technology asset",
                        "âœ… Research publication opportunities"
                    ]
                },
                
                "market_positioning": {
                    "aciklama": "TÃ¼rkÃ§e AI market'inde positioning",
                    "market_avantajlari": [
                        "âœ… Turkish AI leadership position",
                        "âœ… Government/enterprise appeal", 
                        "âœ… Academic collaboration opportunities",
                        "âœ… International recognition potential"
                    ]
                },
                
                "long_term_investment": {
                    "aciklama": "Uzun vadeli yatÄ±rÄ±m deÄŸeri",
                    "yatirim_getirileri": [
                        "âœ… Reusable across multiple projects",
                        "âœ… Foundation for Turkish AI ecosystem",
                        "âœ… Technology stack ownership",
                        "âœ… Independent from external dependencies"
                    ]
                }
            }
        }
    
    def dezavantajlar_detayli_analiz(self):
        """
        TÃœRKÃ‡E TOKENIZER GELÄ°ÅTÄ°RMENÄ°N DEZAVANTAJLARI
        ============================================
        """
        
        return {
            "GELÄ°ÅTÄ°RME CHALLENGES": {
                "yuksek_gelistirme_maliyeti": {
                    "aciklama": "Ã–nemli zaman ve kaynak yatÄ±rÄ±mÄ±",
                    "maliyet_breakdown": {
                        "insan_kaynaklari": {
                            "nlp_uzman": "2-3 kiÅŸi, 3-6 ay",
                            "yazilim_gelistirici": "1-2 kiÅŸi, 2-4 ay", 
                            "linguist": "1 kiÅŸi, 1-2 ay",
                            "toplam_adam_ay": "8-15 adam/ay"
                        },
                        "hesaplama_kaynaklari": {
                            "data_collection": "100GB+ Turkish corpus",
                            "training_compute": "500-1000 GPU hours",
                            "testing_validation": "200-400 GPU hours"
                        },
                        "tahmini_toplam_maliyet": "$50,000-150,000"
                    }
                },
                
                "teknik_karmasiklik": {
                    "aciklama": "YÃ¼ksek teknik zorluk ve risk",
                    "karmasiklik_alanlari": [
                        "âŒ TÃ¼rkÃ§e morfoloji kompleksitesi",
                        "âŒ Agglutinative language challenges",
                        "âŒ Vocabulary size optimization",
                        "âŒ Quality assurance complexity"
                    ],
                    "risk_faktorleri": [
                        "âš ï¸ Suboptimal tokenization riski",
                        "âš ï¸ Performance regression possibility",
                        "âš ï¸ Compatibility issues potential",
                        "âš ï¸ Maintenance overhead"
                    ]
                },
                
                "dogrulama_zorluklari": {
                    "aciklama": "Kalite ve performance validation zorluklarÄ±",
                    "validation_challenges": [
                        "âŒ Comprehensive Turkish benchmark eksikliÄŸi",
                        "âŒ Multi-domain testing requirements",
                        "âŒ Subjective quality assessment",
                        "âŒ Comparison baseline establishment"
                    ]
                }
            },
            
            "OPERASYONEL RÄ°SKLER": {
                "zaman_riski": {
                    "aciklama": "Proje timeline riskleri",
                    "zaman_risk_faktorleri": [
                        "âŒ Unexpected technical challenges",
                        "âŒ Quality iteration cycles",
                        "âŒ Testing ve validation delays",
                        "âŒ Resource availability issues"
                    ],
                    "gecikme_ihtimali": "30-50% timeline extension riski"
                },
                
                "performans_riski": {
                    "aciklama": "Beklenen performance'a ulaÅŸamama riski",
                    "performans_risk_alanlari": [
                        "âŒ Tokenization quality dÃ¼ÅŸÃ¼klÃ¼ÄŸÃ¼",
                        "âŒ Model compatibility issues",
                        "âŒ Inference speed degradation",
                        "âŒ Memory usage optimization problems"
                    ],
                    "basarisizlik_ihtimali": "15-25%"
                },
                
                "kaynak_riski": {
                    "aciklama": "Kaynak yetersizliÄŸi riskleri",
                    "kaynak_risk_faktorleri": [
                        "âŒ Expert talent scarcity",
                        "âŒ Computational resource constraints",
                        "âŒ High-quality Turkish data limitations",
                        "âŒ Budget overrun possibilities"
                    ]
                }
            },
            
            "ALTERNATÄ°F MALIYET": {
                "firsat_maliyeti": {
                    "aciklama": "Hibrit yaklaÅŸÄ±m vs Ã¶zel tokenizer opportunity cost",
                    "karsilastirma": {
                        "hibrit_yaklasim": {
                            "sure": "1-3 hafta",
                            "maliyet": "$5,000-15,000",
                            "basari_orani": "80-90%",
                            "risk": "DÃ¼ÅŸÃ¼k"
                        },
                        "ozel_tokenizer": {
                            "sure": "6-24 hafta", 
                            "maliyet": "$50,000-150,000",
                            "basari_orani": "60-85%",
                            "risk": "YÃ¼ksek"
                        }
                    }
                },
                
                "pazar_zamanlamasi": {
                    "aciklama": "Market timing ve competitive advantage kaybÄ±",
                    "zamanlamasi_riskleri": [
                        "âŒ Competitor solutions Ã¶ne geÃ§ebilir",
                        "âŒ Customer demand timing miss",
                        "âŒ Technology obsolescence riski",
                        "âŒ First-mover advantage kaybÄ±"
                    ]
                }
            }
        }
    
    def hibrit_vs_ozel_tokenizer_karsilastirma(self):
        """
        HÄ°BRÄ°T YAKLAÅIM VS Ã–ZEL TOKENIZER KARÅILAÅTIRMASI
        ================================================
        """
        
        return {
            "KARÅILAÅTIRMA MATRÄ°SÄ°": {
                "gelistirme_suresi": {
                    "hibrit_yaklasim": "1-3 hafta",
                    "ozel_tokenizer": "6-24 hafta",
                    "kazanan": "HÄ°BRÄ°T (8x daha hÄ±zlÄ±)"
                },
                
                "maliyet": {
                    "hibrit_yaklasim": "$5,000-15,000", 
                    "ozel_tokenizer": "$50,000-150,000",
                    "kazanan": "HÄ°BRÄ°T (10x daha ucuz)"
                },
                
                "basari_orani": {
                    "hibrit_yaklasim": "80-90%",
                    "ozel_tokenizer": "60-85%", 
                    "kazanan": "HÄ°BRÄ°T (daha gÃ¼venilir)"
                },
                
                "teknik_risk": {
                    "hibrit_yaklasim": "DÃ¼ÅŸÃ¼k-Orta",
                    "ozel_tokenizer": "YÃ¼ksek",
                    "kazanan": "HÄ°BRÄ°T (dÃ¼ÅŸÃ¼k risk)"
                },
                
                "turkce_optimizasyon": {
                    "hibrit_yaklasim": "Ä°yi (adaptive strategies ile)",
                    "ozel_tokenizer": "MÃ¼kemmel (teorik)",
                    "kazanan": "Ã–ZEL TOKENIZER (maximum potential)"
                },
                
                "uzun_vadeli_deger": {
                    "hibrit_yaklasim": "Orta (external dependency)",
                    "ozel_tokenizer": "YÃ¼ksek (IP ownership)",
                    "kazanan": "Ã–ZEL TOKENIZER (strategic value)"
                }
            },
            
            "SENARYO BAZLI Ã–NERÄ°LER": {
                "acil_proje_ihtiyaci": {
                    "durum": "2-4 hafta iÃ§inde working solution gerekli",
                    "oneri": "HÄ°BRÄ°T YAKLAÅIM",
                    "sebep": "HÄ±zlÄ±, gÃ¼venilir sonuÃ§ garantisi"
                },
                
                "kalite_odakli_proje": {
                    "durum": "En yÃ¼ksek TÃ¼rkÃ§e performance hedefi",
                    "oneri": "Ã–ZEL TOKENIZER (uzun vadeli yatÄ±rÄ±m)",
                    "sebep": "Maximum Turkish optimization potential"
                },
                
                "budjet_kisitli_proje": {
                    "durum": "SÄ±nÄ±rlÄ± bÃ¼tÃ§e ve kaynak",
                    "oneri": "HÄ°BRÄ°T YAKLAÅIM",
                    "sebep": "10x daha dÃ¼ÅŸÃ¼k maliyet"
                },
                
                "stratejik_yatirim": {
                    "durum": "TÃ¼rkÃ§e AI leadership hedefi",
                    "oneri": "Ã–ZEL TOKENIZER",
                    "sebep": "IP ownership ve competitive advantage"
                },
                
                "risk_averse_organizasyon": {
                    "durum": "DÃ¼ÅŸÃ¼k risk tolerance",
                    "oneri": "HÄ°BRÄ°T YAKLAÅIM",
                    "sebep": "Proven methods, predictable outcomes"
                }
            }
        }
    
    def oneri_ve_karar_matrisi(self):
        """
        Ã–NERÄ° VE KARAR MATRÄ°SÄ°
        ======================
        """
        
        return {
            "KARAR VERÄ°CÄ° FRAMEWORK": {
                "kisa_vadeli_hedefler": {
                    "hizli_mvp": "HÄ°BRÄ°T YAKLAÅIM",
                    "immediate_roi": "HÄ°BRÄ°T YAKLAÅIM", 
                    "proof_of_concept": "HÄ°BRÄ°T YAKLAÅIM"
                },
                
                "uzun_vadeli_hedefler": {
                    "market_leadership": "Ã–ZEL TOKENIZER",
                    "ip_portfolio": "Ã–ZEL TOKENIZER",
                    "technology_stack_ownership": "Ã–ZEL TOKENIZER"
                },
                
                "hibrit_strateji": {
                    "asamali_yaklasim": [
                        "Fase 1: Hibrit yaklaÅŸÄ±m ile hÄ±zlÄ± MVP (1-3 hafta)",
                        "Fase 2: Market validation ve user feedback",
                        "Fase 3: Ã–zel tokenizer development (parallel)",
                        "Fase 4: Migration ve optimization"
                    ],
                    "avantajlari": [
                        "âœ… Immediate time-to-market",
                        "âœ… Risk mitigation",
                        "âœ… Continuous value delivery",
                        "âœ… Learning-based optimization"
                    ]
                }
            },
            
            "FÄ°NAL Ã–NERÄ°": {
                "aninda_baslangic": {
                    "yaklasim": "PARALEL HÄ°BRÄ°T APPROACH",
                    "sebep": "Immediate results, 80-90% success rate",
                    "timeline": "2-3 hafta",
                    "expected_loss": "1.5-3.0 (current 5.2383'ten bÃ¼yÃ¼k iyileÅŸtirme)"
                },
                
                "paralel_gelistirme": {
                    "yaklasim": "Ã–zel tokenizer R&D baÅŸlat",
                    "sebep": "Long-term strategic investment",
                    "timeline": "6-12 ay",
                    "expected_outcome": "Maximum Turkish optimization"
                },
                
                "migration_strategy": {
                    "adim_1": "Hibrit yaklaÅŸÄ±m ile production'a Ã§Ä±k",
                    "adim_2": "User feedback ve performance data topla",
                    "adim_3": "Ã–zel tokenizer develop et",
                    "adim_4": "A/B test ile migration yap"
                }
            }
        }
    
    def sonuc_ve_tavsiyeler(self):
        """
        SONUÃ‡ VE TAVSÄ°YELER
        ==================
        """
        
        return {
            "Ã–ZET DEÄERLENDÄ°RME": {
                "hibrit_yaklasim_guclu_yonleri": [
                    "âœ… HÄ±zlÄ± implementation (1-3 hafta)",
                    "âœ… DÃ¼ÅŸÃ¼k risk ve maliyet", 
                    "âœ… YÃ¼ksek baÅŸarÄ± oranÄ± (80-90%)",
                    "âœ… Immediate problem solving"
                ],
                
                "ozel_tokenizer_guclu_yonleri": [
                    "âœ… Maximum Turkish optimization",
                    "âœ… IP ownership ve strategic value",
                    "âœ… Long-term competitive advantage",
                    "âœ… Perfect Qwen3 compatibility"
                ],
                
                "optimal_strateji": "HIBRIT BAÅLANGIÃ‡ + PARALEL TOKENIZER GELIÅTIRME"
            },
            
            "EYLEM PLANI": {
                "week_1_2": "Paralel hibrit yaklaÅŸÄ±m implementation",
                "week_3_4": "Production deployment ve performance monitoring",
                "month_2_3": "Ã–zel tokenizer research ve development baÅŸlangÄ±cÄ±",
                "month_4_12": "Tokenizer development ve testing",
                "month_12+": "Migration planning ve execution"
            },
            
            "RISK MÄ°TÄ°GATION": {
                "hibrit_basarÄ±sÄ±zligi": "Emergency fallback: Original tokenizer",
                "tokenizer_gelistirme_basarisizligi": "Hibrit solution production'da kalÄ±r",
                "budget_asimi": "Phased development approach",
                "timeline_gecikmeleri": "Agile development methodology"
            }
        }

def main():
    """Ana analiz raporu"""
    
    analiz = Qwen3UyumluTurkceTokenizerAnalizi()
    
    print("ğŸ¯ QWEN3 UYUMLU TÃœRKÃ‡E TOKENIZER GELÄ°ÅTÄ°RME ANALÄ°ZÄ°")
    print("=" * 70)
    print("Mevcut Problem: turkish_mixtral_v3_fixed â†” Qwen3 uyumsuzluÄŸu")
    print("Ã‡Ã¶zÃ¼m Analizi: Hibrit yaklaÅŸÄ±m vs Ã–zel tokenizer geliÅŸtirme")
    print("=" * 70)
    
    # Temel yaklaÅŸÄ±mlar
    yaklasimlar = analiz.gelistirme_yaklasimlari()
    print("\nğŸ“Š TOKENIZER GELÄ°ÅTÄ°RME YAKLAÅIMLARI:")
    for yaklasim, detay in yaklasimlar.items():
        print(f"\n{yaklasim}:")
        print(f"  â€¢ {detay['aciklama']}")
        print(f"  â€¢ SÃ¼re: {detay['gelistirme_suresi']}")
        print(f"  â€¢ Zorluk: {detay['zorluk_seviyesi']}")
        print(f"  â€¢ BaÅŸarÄ±: {detay['basari_ihtimali']}")
    
    # Avantajlar
    avantajlar = analiz.avantajlar_detayli_analiz()
    print(f"\nâœ… Ã–ZEL TOKENIZER GELÄ°ÅTÄ°RME AVANTAJLARI:")
    print("-" * 50)
    for kategori, detaylar in avantajlar.items():
        print(f"\n{kategori}:")
        for alan, bilgi in detaylar.items():
            print(f"  â€¢ {alan}: {bilgi.get('aciklama', 'Detay analizi mevcut')}")
    
    # Dezavantajlar  
    dezavantajlar = analiz.dezavantajlar_detayli_analiz()
    print(f"\nâŒ Ã–ZEL TOKENIZER GELÄ°ÅTÄ°RME DEZAVANTAJLARI:")
    print("-" * 50)
    for kategori, detaylar in dezavantajlar.items():
        print(f"\n{kategori}:")
        for alan, bilgi in detaylar.items():
            print(f"  â€¢ {alan}: {bilgi.get('aciklama', 'Risk analizi mevcut')}")
    
    # KarÅŸÄ±laÅŸtÄ±rma
    karsilastirma = analiz.hibrit_vs_ozel_tokenizer_karsilastirma()
    print(f"\nâš–ï¸ HÄ°BRÄ°T vs Ã–ZEL TOKENIZER KARÅILAÅTIRMA:")
    print("-" * 50)
    matris = karsilastirma["KARÅILAÅTIRMA MATRÄ°SÄ°"]
    for kriter, degerler in matris.items():
        print(f"\n{kriter.upper()}:")
        print(f"  Hibrit: {degerler['hibrit_yaklasim']}")
        print(f"  Ã–zel: {degerler['ozel_tokenizer']}")
        print(f"  ğŸ† Kazanan: {degerler['kazanan']}")
    
    # Final Ã¶neri
    oneri = analiz.oneri_ve_karar_matrisi()
    final_oneri = oneri["FÄ°NAL Ã–NERÄ°"]
    print(f"\nğŸ¯ FÄ°NAL Ã–NERÄ°:")
    print("-" * 30)
    print(f"ğŸ“ˆ AnÄ±nda: {final_oneri['aninda_baslangic']['yaklasim']}")
    print(f"   Sebep: {final_oneri['aninda_baslangic']['sebep']}")
    print(f"   Timeline: {final_oneri['aninda_baslangic']['timeline']}")
    print(f"\nğŸ”¬ Paralel: {final_oneri['paralel_gelistirme']['yaklasim']}")
    print(f"   Sebep: {final_oneri['paralel_gelistirme']['sebep']}")
    print(f"   Timeline: {final_oneri['paralel_gelistirme']['timeline']}")
    
    # SonuÃ§
    sonuc = analiz.sonuc_ve_tavsiyeler()
    optimal = sonuc["Ã–ZET DEÄERLENDÄ°RME"]["optimal_strateji"]
    print(f"\nğŸ† OPTIMAL STRATEJÄ°: {optimal}")
    
    return {
        'yaklasimlar': yaklasimlar,
        'avantajlar': avantajlar,
        'dezavantajlar': dezavantajlar,
        'karsilastirma': karsilastirma,
        'final_oneri': oneri,
        'sonuc': sonuc
    }

if __name__ == "__main__":
    analiz_sonuclari = main()